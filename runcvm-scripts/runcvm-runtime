#!/opt/runcvm/bin/bash

# REFERENCES

# Qemu:
# - https://github.com/joshkunz/qemu-docker
# - https://mergeboard.com/blog/2-qemu-microvm-docker/
# - https://github.com/BBVA/kvm

# Virtiofs
# - https://vmsplice.net/~stefan/virtio-fs_%20A%20Shared%20File%20System%20for%20Virtual%20Machines.pdf
# - https://virtio-fs.gitlab.io/howto-qemu.html
# - https://www.tauceti.blog/posts/qemu-kvm-share-host-directory-with-vm-with-virtio/

# Container config.json spec
# - https://github.com/opencontainers/runtime-spec/
# - https://github.com/opencontainers/runtime-spec/blob/main/config.md

# Mount namespaces
# - https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt
# - https://www.redhat.com/sysadmin/mount-namespaces

LOG=/tmp/runcvm.log
RUNCVM=/opt/runcvm
RUNCVM_JQ=$RUNCVM/usr/bin/jq
RUNCVM_VM_MOUNTPOINT="/vm"
RUNCVM_ENTRYPOINT=$RUNCVM/scripts/runcvm-ctr-entrypoint
RUNCVM_EXEC=$RUNCVM/scripts/runcvm-ctr-exec
RUNCVM_KERNELS=$RUNCVM/kernels
RUNCVM_KERNEL_DEFAULT=debian
RUNCVM_MEM_SIZE_DEFAULT="512M"
RUNCVM_DEBUG=1

debug() {
  [ -n "$RUNCVM_DEBUG" ] && true || false
}

log() {
  debug && echo "$@" >>$LOG
}

error() {

  # Skip past any docker error ending in CR
  (echo; echo) >&2

  # Dump message to stderr
  echo "RunCVM: Error: $1" >&2

  #Â Dump error also to the logfile
  log "RunCVM: Error: $1"
  exit -1
}

load_env_from_file() {
  local file="$1"
  local var="$2"

  # Return gracefully if no $file exists
  if ! [ -f "$file" ]; then
    return 0
  fi

  while read LINE
  do
    local name="${LINE%%=*}"
    local value="${LINE#*=}"
    
    if [ "$name" != "$LINE" ] && [ "$value" != "$LINE" ] && [ "$name" = "$var" ]; then
      # We found variable $name: return it, removing any leading/trailing double quotes
      echo "$value" | sed 's/^"//;s/"$//'
      return 0
    fi
  done <"$file"
  
  return 1
}

jq() {
    $RUNCVM_JQ "$@"
}

jq_set() {
  local file="$1"
  shift
  
  local tmp="/tmp/config.json.$$"

  if jq "$@" $file >$tmp; then
    mv $tmp $file
  else
    echo "Failed to update $(basename $file); aborting!" 2>&1
    exit 1
  fi
}

jq_get() {
  local file="$1"
  shift
  
  jq -r "$@" $file
}

get_process_env_boolean() {
  local file="$1"
  local var="$2"
  local value=$(jq_get "$file" --arg env "$var" '.env[] | select(match("^" + $env + "=")) | match("^" + $env + "=(.*)") | .captures[] | .string')
  
  [ -n "$value" ] && echo "1" || echo "0"
}

get_config_env() {
  local var="$1"
  local default="$2"
  local value=$(jq_get "$CFG" --arg env "$var" '.process.env[] | select(match("^" + $env + "=")) | match("^" + $env + "=(.*)") | .captures[] | .string')
  
  [ -n "$value" ] && echo -n "$value" || echo -n "$default"
}

set_config_env() {
  local var="$1"
  local value="$2"
  
  jq_set "$CFG" --arg env "$var=$value" '.process.env |= (.+ [$env] | unique)'
}


# PARSE RUNC GLOBAL OPTIONS:
# --debug             enable debug logging
# --log value         set the log file to write runc logs to (default is '/dev/stderr')
# --log-format value  set the log format ('text' (default), or 'json') (default: "text")
# --root value        root directory for storage of container state (this should be located in tmpfs) (default: "/run/user/1000/runc")
# --criu value        path to the criu binary used for checkpoint and restore (default: "criu")
# --systemd-cgroup    enable systemd cgroup support, expects cgroupsPath to be of form "slice:prefix:name" for e.g. "system.slice:runc:434234"
# --rootless value    ignore cgroup permission errors ('true', 'false', or 'auto') (default: "auto")

COMMAND_LINE=("$@")

debug && log "--- LOG BEGINS ---"
echo "Command line: $0 ${COMMAND_LINE[@]@Q}" >>$LOG

while true
do
  case "$1" in
    --debug|--systemd-cgroup) shift; continue; ;;
    --log|--log-format|--root|--criu|--rootless) shift; shift; continue; ;;
    --log=*|--log-format=*|--root=*|--criu=*|--rootless=*) shift; continue; ;;
    *) break; ;;
  esac
done

COMMAND="$1"
shift

if [ "$COMMAND" = "create" ]; then

  debug && log "Command: create"
  
  # USAGE:
  #    runc create [command options] <container-id>
  #   
  # PARSE 'create' COMMAND OPTIONS
  # --bundle value, -b value  path to the root of the bundle directory, defaults to the current directory
  # --console-socket value    path to an AF_UNIX socket which will receive a file descriptor referencing the master end of the console's pseudoterminal
  # --pid-file value          specify the file to write the process id to
  # --no-pivot                do not use pivot root to jail process inside rootfs.  This should be used whenever the rootfs is on top of a ramdisk
  # --no-new-keyring          do not create a new session keyring for the container.  This will cause the container to inherit the calling processes session key
  # --preserve-fds value      Pass N additional file descriptors to the container (stdio + $LISTEN_FDS + N in total) (default: 0)
  while true
  do
    case "$1" in
      --bundle|-b) shift; BUNDLE="$1"; shift; continue; ;;
      --console-socket|--pid-file|--preserve-fds) shift; shift; continue; ;;
      --no-pivot|--no-new-keyring) shift; continue; ;;
      *) break; ;;
    esac
  done

  ID="$1"


  CFG="$BUNDLE/config.json"
  ROOT=$(jq -r .root.path $CFG)

  if debug; then
    log "Command: create bundle=$BUNDLE id=$ID root=$ROOT"
    
    # Save formatted config.json
    jq -r . <$CFG >/tmp/config.json-$$-1
    
  fi

  # [UNIMPLEMENTED] LAUNCH virtiofsd ON HOST INSTEAD OF CONTAINER
  #
  # Optionally, launch virtiofsd on host and bind-mount socket into container
  # HOST_SOCKET="/tmp/.virtiofs-$ID.sock"
  # touch $HOST_SOCKET
  # /usr/lib/qemu/virtiofsd --socket-path=$HOST_SOCKET -o cache=always -o source=$ROOT >/tmp/virtiofsd.log 2>&1 &  
  
  ARG0=$(jq_get "$CFG" '.process.args[0]')
  # Now look in mounts for destination == $ARG0 (this works for Docker and Podman)
  if [ "$ARG0" = "/sbin/docker-init" ] || [ "$ARG0" = "/dev/init" ]; then
  
    # User intended an init process to be run in the container,
    # so arrange to run our own instead, that will launch the original entrypoint
    
    # Look for and remove a mountpoint for this process.
    jq_set "$CFG" --arg init "$ARG0" '(.mounts[] | select(.destination == $init)) |= empty'
    
    # Replace the first argument with our own entrypoint; and remove the second, '--' (for now, #TODO)
    jq_set "$CFG" --arg entrypoint "$RUNCVM_ENTRYPOINT" '.process.args[0] = $entrypoint | del(.process.args[1])'
    
    # We know the user intended an init process to be run in the container.
    # TODO: We might want to indicate this, so that our entrypoint does not skip doing this
    # if the original entrypoint also looks like an init process.
    set_config_env "RUNCVM_INIT" "1"
  else
    # We don't know if the original entrypoint is an init process or not.
    # Run our entrypoint first to work this out and do the right thing.
    
    jq_set "$CFG" --arg entrypoint "$RUNCVM_ENTRYPOINT" '.process.args |= [$entrypoint] + .'
  fi

  # SET RUNCVM_HAS_HOME
  # 
  # If the HOME env var was not set either in the image, or via docker run, 
  # then it will be missing in the config env. Detect this case for communication to runcvm-ctr-entrypoint
  # so that HOME can be set to the requested user's default homedir.
  #
  # - See runcvm-ctr-entrypoint for full details of how/why hasHome is needed and HOME gets set.
  if [ -n "$(get_config_env HOME)" ]; then
    set_config_env "RUNCVM_HAS_HOME" "1"
  else
    set_config_env "RUNCVM_HAS_HOME" "0"
  fi

  # CONFIGURE USER
  # - Must be root to run container
  RUNCVM_UIDGID=$(jq_get "$CFG" '(.process.user.uid | tostring) + ":" + (.process.user.gid | tostring) + ":" + ((.process.user.additionalGids // []) | join(","))')
  set_config_env "RUNCVM_UIDGID" "$RUNCVM_UIDGID"
  jq_set "$CFG" '.process.user = {"uid":0, "gid":0}'
  log "RUNCVM_UIDGID=$RUNCVM_UIDGID"

  # CONFIGURE CPUS
  RUNCVM_CPUS=$(( $(jq_get "$CFG" '.linux.resources.cpu.quota') / 100000))
  set_config_env "RUNCVM_CPUS" "$RUNCVM_CPUS"
  log "RUNCVM_CPUS=$RUNCVM_CPUS"

  # CONFIGURE MOUNTS
  set_config_env "RUNCVM_VM_MOUNTPOINT" "$RUNCVM_VM_MOUNTPOINT"

  # First extract list of tmpfs mounts in fstab form, then delete them from the config
  RUNCVM_TMPFS=$(jq_get "$CFG" '( .mounts[] | select(.type == "tmpfs" and (.destination | test("^/dev(/|$)") | not) ) ) | [.source + " " + .destination + " tmpfs " + (.options | map(select(. != "rprivate" and . != "private")) | join(",")) + " 0 0"] | .[0]')
  jq_set "$CFG" -r 'del( .mounts[] | select(.type == "tmpfs" and (.destination | test("^/dev(/|$)") | not) ) )'
  set_config_env "RUNCVM_TMPFS" "$RUNCVM_TMPFS"

  # Rewrite all pre-existing bind/volume mounts (except those at or below /disks) to mount
  # below $RUNCVM_VM_MOUNTPOINT instead of below /.
  #
  # TODO TO CONSIDER:
  # If we excluded /etc/(resolv.conf,hosts,hostname), and moved these to top of the array
  # (by promoting them at the end of the below statements), they would be present in both
  # container and VM.
  #
  # N.B. A mount at or underneath /disks will NOT be mapped to /vm/disks - this path is reserved for mounting disk files to the container
  jq_set "$CFG" --arg vm "$RUNCVM_VM_MOUNTPOINT" '( .mounts[] | select(.type == "bind" and (.destination | test("^/disks(/|$)") | not) ) ).destination |= $vm + .'

  # Mount / from container to $RUNCVM_VM_MOUNTPOINT, recursively binding all pre-existing mount points
  # (these being only the ones defined ahead of this item in the mounts[] array - so order matters!)
  jq_set "$CFG" --arg root "$ROOT" --arg vm "$RUNCVM_VM_MOUNTPOINT" '.mounts |= [{"destination":$vm,"type":"bind","source":$root,"options":["rbind","private","rw"]}] + .'

  # Mount a tmpfs at /.runcvm in container
  # Define this at top of mounts[] so it is recursively mounted
  jq_set "$CFG" '.mounts |= [{"destination":"/.runcvm","type":"tmpfs","source":"runcvm","options":["nosuid","noexec","nodev","size=1M","mode=700"]}] + .'

  # Mount /opt/runcvm from host to container
  # Define this at top of mounts[] so it is recursively mounted
  jq_set "$CFG" --arg runcvm "$RUNCVM" '.mounts |= [{"destination":$runcvm,"type":"bind","source":$runcvm,"options":["bind","private","ro"]}] + .'

  # Mount a tmpfs at /run in container
  # Define this at bottom of mounts[] so it is not recursively mounted to /vm
  jq_set "$CFG" '.mounts += [{"destination":"/run","type":"tmpfs","source":"run","options":["nosuid","noexec","nodev","size=1M","mode=700"]}]'

  # DETERMINE LAUNCH KERNEL:
  #
  # 1. If RUNCVM_KERNEL specified:
  #    - <dist> or <dist>/latest - use latest RUNCVM kernel available for this dist *and* ARGS
  #    - <dist>/<version> - use specific RUNCVM kernel version for this dist *and* ARGS
  # 2. Else, check /etc/os-release and:
  #    a. Use builtin kernel for this dist (if present in the expected location) *and* ARGS
  #    b. Use latest RUNCVM kernel available for the dist:
  #      - ID=alpine, VERSION_ID=3.16.0 => alpine/latest
  #      - ID=debian, VERSION_ID=11     => debian/latest
  #      - ID=ubuntu, VERSION_ID=22.04  => ubuntu/latest
  
  # Look for RUNCVM_KERNEL env var
  RUNCVM_KERNEL=$(get_config_env 'RUNCVM_KERNEL')
  log "RUNCVM_KERNEL=$RUNCVM_KERNEL (1)"

  if [ -n "$RUNCVM_KERNEL" ]; then
    # If found, validate

    if [[ "$RUNCVM_KERNEL" =~ ^[a-z]+$ ]]; then
      RUNCVM_KERNEL+="/latest"
    fi
  
    if [[ "$RUNCVM_KERNEL" =~ \.\. ]]; then
      error "Kernel '$RUNCVM_KERNEL' invalid (contains '..')"
    fi
  
    if ! [[ "$RUNCVM_KERNEL" =~ ^[a-z]+(/[^/]+)?$ ]]; then
      error "Kernel '$RUNCVM_KERNEL' invalid (should match ^[a-z]+(/[^/]+)?$)"
    fi
  
    if ! [ -d "$RUNCVM_KERNELS/$RUNCVM_KERNEL" ]; then
      error "Kernel '$RUNCVM_KERNEL' not found (check $RUNCVM_KERNELS)"
    fi

    RUNCVM_KERNEL_ID=$(dirname "$RUNCVM_KERNEL") # Returns e.g. alpine, debian, ubuntu

  else
    # If not found, look for value from /etc/os-release in the container image
    
    RUNCVM_KERNEL_ID=$(load_env_from_file "$ROOT/etc/os-release" "ID")

    # Currently unused
    # RUNCVM_KERNEL_OS_VERSION_ID=$(load_var_from_env "$ROOT/etc/os-release" "VERSION_ID")

    # If still not found, assign a default
    if [ -z "$RUNCVM_KERNEL_ID" ]; then
      RUNCVM_KERNEL_ID="${RUNCVM_KERNEL_DEFAULT:-debian}"
    fi

    RUNCVM_KERNEL="$RUNCVM_KERNEL_ID/latest"
  fi
  
  log "RUNCVM_KERNEL=$RUNCVM_KERNEL (2)"
  log "RUNCVM_KERNEL_ID=$RUNCVM_KERNEL_ID"
  log "RUNCVM_KERNEL_VERSION=$RUNCVM_KERNEL_VERSION"
  
  # Now look up the default kernel and initramfs paths and args for this kernel
  case "$RUNCVM_KERNEL_ID" in
      debian) RUNCVM_KERNEL_OS_KERNEL_PATH="/vmlinuz"
              RUNCVM_KERNEL_OS_INITRAMFS_PATH="/initrd.img"
              RUNCVM_KERNEL_ROOT="rootfstype=virtiofs root=myfs noresume nomodeset"
              ;;
      ubuntu) RUNCVM_KERNEL_OS_KERNEL_PATH="/boot/vmlinuz"
              RUNCVM_KERNEL_OS_INITRAMFS_PATH="/boot/initrd.img"
              RUNCVM_KERNEL_ROOT="rootfstype=virtiofs root=myfs noresume nomodeset"
              ;;
          ol) RUNCVM_KERNEL_OS_KERNEL_PATH="/boot/vmlinuz"
              RUNCVM_KERNEL_OS_INITRAMFS_PATH="/boot/initramfs"
              RUNCVM_KERNEL_ROOT="root=virtiofs:myfs noresume nomodeset"
              ;;
      alpine) RUNCVM_KERNEL_OS_KERNEL_PATH="/boot/vmlinuz-virt"
              RUNCVM_KERNEL_OS_INITRAMFS_PATH="/boot/initramfs-virt"
              RUNCVM_KERNEL_ROOT="rootfstype=virtiofs root=myfs resume= nomodeset"
              ;;

           *) error "Unrecognised image O/S '$RUNCVM_KERNEL'; specify --env=RUNCVM_KERNEL=<dist> or --env=RUNCVM_KERNEL=<dist>/<version>"; ;;
  esac
  
  # Look for a kernel and initramfs at the expected paths in the container image.
  if [[ -f "$ROOT/$RUNCVM_KERNEL_OS_KERNEL_PATH" && -f "$ROOT/$RUNCVM_KERNEL_OS_INITRAMFS_PATH" ]]; then
    RUNCVM_KERNEL_PATH="$RUNCVM_KERNEL_OS_KERNEL_PATH"
    RUNCVM_KERNEL_INITRAMFS_PATH="$RUNCVM_KERNEL_OS_INITRAMFS_PATH"
  else
    # If we didn't find a kernel and initramfs at the expected paths in the container image,
    # select the latest RUNCVM kernel version and arrange to mount it.

    RUNCVM_KERNEL_VERSION=$(basename $(readlink -f "$RUNCVM_KERNELS/$RUNCVM_KERNEL")) # Returns e.g. 5.15.53-0-virt

    RUNCVM_KERNEL_MOUNT_LIB_MODULES=$(get_config_env 'RUNCVM_KERNEL_MOUNT_LIB_MODULES')
    if [ -n "$RUNCVM_KERNEL_MOUNT_LIB_MODULES" ]; then
      RUNCVM_KERNEL_MODULES_SRC="$RUNCVM_KERNELS/$RUNCVM_KERNEL_ID/$RUNCVM_KERNEL_VERSION/modules"
      RUNCVM_KERNEL_MODULES_DST="/lib/modules"
    else
      RUNCVM_KERNEL_MODULES_SRC="$RUNCVM_KERNELS/$RUNCVM_KERNEL_ID/$RUNCVM_KERNEL_VERSION/modules/$RUNCVM_KERNEL_VERSION"
      RUNCVM_KERNEL_MODULES_DST="/lib/modules/$RUNCVM_KERNEL_VERSION"
    fi
    
    RUNCVM_KERNEL_PATH="$RUNCVM_KERNELS/$RUNCVM_KERNEL_ID/$RUNCVM_KERNEL_VERSION/vmlinuz"
    RUNCVM_KERNEL_INITRAMFS_PATH="$RUNCVM_KERNELS/$RUNCVM_KERNEL_ID/$RUNCVM_KERNEL_VERSION/initrd"

    jq_set "$CFG" --arg modules_dst "$RUNCVM_VM_MOUNTPOINT$RUNCVM_KERNEL_MODULES_DST" --arg modules_src "$RUNCVM_KERNEL_MODULES_SRC" '.mounts += [{"destination":$modules_dst,"type":"bind","source":$modules_src,"options":["bind","private","ro"]}]'
  fi

  log "RUNCVM_KERNEL=$RUNCVM_KERNEL"
  log "RUNCVM_KERNEL_ID=$RUNCVM_KERNEL_ID"
  log "RUNCVM_KERNEL_VERSION=$RUNCVM_KERNEL_VERSION"
  log "RUNCVM_KERNEL_OS_KERNEL_PATH=$RUNCVM_KERNEL_OS_KERNEL_PATH"
  log "RUNCVM_KERNEL_OS_INITRAMFS_PATH=$RUNCVM_KERNEL_OS_INITRAMFS_PATH"
  log "RUNCVM_KERNEL_PATH=$RUNCVM_KERNEL_PATH"
  log "RUNCVM_KERNEL_INITRAMFS_PATH=$RUNCVM_KERNEL_INITRAMFS_PATH"
  log "RUNCVM_KERNEL_ROOT=$RUNCVM_KERNEL_ROOT"
  log "RUNCVM_KERNEL_MODULES_SRC=$RUNCVM_KERNEL_MODULES_SRC"
  log "RUNCVM_KERNEL_MODULES_DST=$RUNCVM_KERNEL_MODULES_DST"
  
  set_config_env "RUNCVM_KERNEL_PATH" "$RUNCVM_KERNEL_PATH"
  set_config_env "RUNCVM_KERNEL_INITRAMFS_PATH" "$RUNCVM_KERNEL_INITRAMFS_PATH"
  set_config_env "RUNCVM_KERNEL_ROOT" "$RUNCVM_KERNEL_ROOT"

  # Configure devices
  jq_set "$CFG" '.linux.resources.devices += [{"allow":true,"type":"c","major":10,"minor":232,"access":"rwm"},{"allow":true,"type":"c","major":10,"minor":200,"access":"rwm"}]'
  jq_set "$CFG" '.linux.devices+=[{"path":"/dev/net/tun","type":"c","major":10,"minor":200,"fileMode":8630,"uid":0,"gid":0},{"path":"/dev/kvm","type":"c","major":10,"minor":232,"fileMode":8630,"uid":0,"gid":0}]'
  
  # For now, hardcode --security-opt=seccomp=unconfined;
  # later, we can work out the minimal seccomp permissions required.
  jq_set "$CFG" '.linux.seccomp |= empty'
  
  # CONFIGURE MEMORY
  # Set /dev/shm to RUNCVM_MEM_SIZE env var, or to default
  # - it should be large enough to support VM memory
  RUNCVM_MEM_LIMIT=$(jq_get "$CFG" '.linux.resources.memory.limit')
  log "RUNCVM_MEM_LIMIT=$RUNCVM_MEM_LIMIT"
  if [ "$RUNCVM_MEM_LIMIT" != "null" ]; then
    RUNCVM_MEM_SIZE="$(( $RUNCVM_MEM_LIMIT/1024/1024 ))M"
  else
    RUNCVM_MEM_SIZE="$RUNCVM_MEM_SIZE_DEFAULT"
  fi
  log "RUNCVM_MEM_SIZE=$RUNCVM_MEM_SIZE"
  set_config_env "RUNCVM_MEM_SIZE" "$RUNCVM_MEM_SIZE"
  jq_set "$CFG" --arg size "$RUNCVM_MEM_SIZE" '( .mounts[] | select(.destination == "/dev/shm") ) = {"destination": "/dev/shm","type": "tmpfs","source": "shm","options": ["nosuid","noexec","nodev","mode=1777","size=" + $size]}'

  # In future, set the container memory limit to something reasonable to support
  # QEMU + virtiofsd + dnsmasq. Perhaps $RUNCVM_MEM_LIMIT+K (or vice-versa, reduce
  # RUNCVM_MEM_SIZE by K), where K is the memory requirement for the container's processes
  # over and above QEMU.
  # jq_set "$CFG" --arg size $(($RUNCVM_MEM_LIMIT + )) '.linux.resources.memory.limit |= ($size | tonumber)'

  # Add non-default capabilities needed by:
  # - Docker: CAP_NET_ADMIN
  # - Podman: CAP_NET_ADMIN, CAP_NET_RAW, CAP_MKNOD, CAP_AUDIT_WRITE
  for field in bounding effective permitted
  do
    jq_set "$CFG" --arg field "bounding" '.process.capabilities[$field] |= (.+ ["CAP_NET_ADMIN","CAP_NET_RAW","CAP_MKNOD","CAP_AUDIT_WRITE"] | unique)'
  done
  
  # Filter for RUNCVM_SYS_ADMIN=1
  RUNCVM_SYS_ADMIN=$(get_config_env "RUNCVM_SYS_ADMIN")
  if [ "$RUNCVM_SYS_ADMIN" = "1" ]; then
    # TODO use 'unique'
    jq_set "$CFG" '.process.capabilities.bounding += ["CAP_SYS_ADMIN"] | .process.capabilities.effective += ["CAP_SYS_ADMIN"] | .process.capabilities.permitted += ["CAP_SYS_ADMIN"]'
  fi

  debug && cp -a $CFG /tmp/config.json-$$-2
  
elif [ "$COMMAND" = "exec" ]; then

  debug && log "Command: exec"

  # USAGE:
  #   runc exec [command options] <container-id> <command> [command options]  || -p process.json <container-id>
  #
  # PARSE 'exec' COMMAND OPTIONS
  # --console-socket value             path to an AF_UNIX socket which will receive a file descriptor referencing the master end of the console's pseudoterminal
  # --cwd value                        current working directory in the container
  # --env value, -e value              set environment variables
  # --tty, -t                          allocate a pseudo-TTY
  # --user value, -u value             UID (format: <uid>[:<gid>])
  # --additional-gids value, -g value  additional gids
  # --process value, -p value          path to the process.json
  # --detach, -d                       detach from the container's process
  # --pid-file value                   specify the file to write the process id to
  # --process-label value              set the asm process label for the process commonly used with selinux
  # --apparmor value                   set the apparmor profile for the process
  # --no-new-privs                     set the no new privileges value for the process
  # --cap value, -c value              add a capability to the bounding set for the process
  # --preserve-fds value               Pass N additional file descriptors to the container (stdio + $LISTEN_FDS + N in total) (default: 0)
  # --cgroup value                     run the process in an (existing) sub-cgroup(s). Format is [<controller>:]<cgroup>.
  # --ignore-paused                    allow exec in a paused container    
  while true
  do
    case "$1" in
      --console-socket|--cwd|--env|-e|--user|-u|--additional-gids|-g|--pid-file|--process-label|--apparmor|--cap|-c|--preserve-fds|--cgroup) shift; shift; continue; ;;
      --tty|-t|--detach|-d|--no-new-privs|--ignore-paused) shift; continue; ;;
      --process|-p) shift; PROCESS="$1"; continue; ;;
      *) break; ;;
    esac
  done

  if debug; then
    log "Command: exec process=$PROCESS"
    
    # Save formatted process.json
    jq -r . <$PROCESS >/tmp/process.json-$$-1
  fi

  ARG1=$(jq_get "$PROCESS" '.args[0]')
  if [ "$ARG1" = "---" ]; then
    jq_set "$PROCESS" 'del(.args[0])'
  else
    uidgid=$(jq_get "$PROCESS" '(.user.uid | tostring) + ":" + (.user.gid | tostring) + ":" + ((.user.additionalGids // []) | join(","))')
    cwd=$(jq_get "$PROCESS" '.cwd')
    hasHome=$(get_process_env_boolean "$PROCESS" 'HOME')

    jq_set "$PROCESS" --arg exec "$RUNCVM_EXEC" --arg uidgid "$uidgid" --arg cwd "$cwd" --arg hasHome "$hasHome" '.args |= [$exec, $uidgid, $cwd, $hasHome] + .'

    # Force root (or whatever user qemu runs as)
    # Force cwd in the container to / 
    jq_set "$PROCESS" '.user = {"uid":0, "gid":0} | .cwd="/"'
  fi
  
  debug && cp -a $PROCESS /tmp/process.json-$$-2
fi

debug && log "--- LOG ENDS ---"

exec /usr/bin/runc "${COMMAND_LINE[@]}"
