# Storage Test Plan - RunCVM Firecracker vs Standard Docker

**Document Version**: 1.0  
**Created**: December 7, 2025  
**Target Phase**: Phase 3 (Weeks 1-4) - Storage & Persistence  
**Test Environments**: Firecracker Mode vs Standard Docker
**Note**: Firecracker mode uses **NFS over TCP** for volume synchronization.

---

## Table of Contents
1. [Test Overview](#test-overview)
2. [Test Environment Setup](#test-environment-setup)
3. [Test Plan Summary](#test-plan-summary)
4. [Detailed Test Cases](#detailed-test-cases)
5. [Performance Benchmarks](#performance-benchmarks)
6. [Verification Methods](#verification-methods)
7. [Expected Results Matrix](#expected-results-matrix)

---

## Test Overview

### Scope
This test plan covers all storage-related features for Docker runtime integration:
- Bind mounts (`-v /host:/container`)
- Named volumes (`docker volume create`)
- tmpfs mounts (`--tmpfs`)
- Volume drivers
- Rootfs caching
- Data persistence

### Test Targets
1. **Standard Docker** - Baseline reference (native Docker runtime)
2. **RunCVM Firecracker Mode** - Target implementation (virtio-blk with NFS over TCP for live sync)

### Success Criteria
- [PASS] All storage operations work identically in both modes
- [PASS] Data persists across container restarts
- [PASS] Performance degradation <10% vs standard Docker
- [PASS] Boot time: Cold <500ms, Warm <150ms (Firecracker only)

---

## Test Environment Setup

### Prerequisites

#### Standard Docker Setup
```bash
# Install Docker
sudo apt-get update
sudo apt-get install -y docker.io

# Verify installation
docker --version
docker run --rm hello-world
```

#### RunCVM Setup (Firecracker)
```bash
# Clone RunCVM repository
git clone https://github.com/yourorg/runcvm.git
cd runcvm

# Build and install
make build
sudo make install

# Verify runcvm runtime
docker info | grep -i runtime
# Should show: runcvm

# Test Firecracker mode
docker run --runtime=runcvm \
  -e RUNCVM_HYPERVISOR=firecracker \
  --rm alpine echo "Firecracker OK"
```

#### Test Data Preparation
```bash
# Create test directories
mkdir -p /tmp/docker-storage-tests/{bind-mounts,volumes,tmpfs}

# Create test files
echo "test-data-v1" > /tmp/docker-storage-tests/bind-mounts/test.txt
echo "shared-data" > /tmp/docker-storage-tests/bind-mounts/shared.txt
dd if=/dev/urandom of=/tmp/docker-storage-tests/bind-mounts/large.bin bs=1M count=100

# Set permissions
chmod -R 755 /tmp/docker-storage-tests
```

---

## Test Plan Summary

### Phase 1: Basic Bind Mounts (Week 1)

| Test ID | Test Name | Standard Docker | Firecracker | Priority |
|---------|-----------|----------------|-------------|----------|
| BM-001 | Simple bind mount (read) | DONE | TARGET | P0 |
| BM-002 | Bind mount (read-write) | DONE | TARGET | P0 |
| BM-003 | Bind mount (read-only) | DONE | TARGET | P0 |
| BM-004 | Multiple bind mounts | DONE | TARGET | P1 |
| BM-005 | Nested directory mounts | DONE | TARGET | P1 |
| BM-006 | File-level bind mount | DONE | TARGET | P2 |
| NFS-001 | NFS Daemon Verification | N/A | TARGET | P0 |

### Phase 2: Named Volumes (Week 2)

| Test ID | Test Name | Standard Docker | Firecracker | Priority |
|---------|-----------|----------------|-------------|----------|
| NV-001 | Create named volume | DONE | TARGET | P0 |
| NV-002 | Use named volume | DONE | TARGET | P0 |
| NV-003 | Volume persistence | DONE | TARGET | P0 |
| NV-004 | Share volume between containers | DONE | TARGET | P1 |
| NV-005 | Volume deletion | DONE | TARGET | P1 |
| NV-006 | Volume inspection | DONE | TARGET | P2 |
| NFS-002 | Concurrent Access (NFS) | DONE | TARGET | P1 |

### Phase 3: tmpfs Mounts (Week 3)

| Test ID | Test Name | Standard Docker | Firecracker | Priority |
|---------|-----------|----------------|-------------|----------|
| TF-001 | Basic tmpfs mount | DONE | TARGET | P1 |
| TF-002 | tmpfs size limit | DONE | TARGET | P1 |
| TF-003 | tmpfs mode/ownership | DONE | TARGET | P2 |
| TF-004 | tmpfs data volatility | DONE | TARGET | P1 |

### Phase 4: Rootfs Caching (Week 3-4)

| Test ID | Test Name | Standard Docker | Firecracker | Priority |
|---------|-----------|----------------|-------------|----------|
| RC-001 | Cold boot performance | DONE | TARGET | P0 |
| RC-002 | Warm boot performance | DONE | TARGET | P0 |
| RC-003 | Cache invalidation | DONE | TARGET | P1 |
| RC-004 | Multi-image caching | DONE | TARGET | P1 |

### Phase 5: Data Persistence (Week 4)

| Test ID | Test Name | Standard Docker | Firecracker | Priority |
|---------|-----------|----------------|-------------|----------|
| DP-001 | Database persistence (MySQL) | DONE | TARGET | P0 |
| DP-002 | Database persistence (PostgreSQL) | DONE | TARGET | P0 |
| DP-003 | Application state persistence | DONE | TARGET | P1 |
| DP-004 | Large file I/O | DONE | TARGET | P1 |

---

## Detailed Test Cases

## Phase 1: Bind Mounts

### BM-001: Simple Bind Mount (Read)

**Objective**: Verify basic read-only bind mount functionality

**Test Steps - Standard Docker**:
```bash
# 1. Create test file
echo "Hello from host" > /tmp/test-read.txt

# 2. Run container with bind mount
docker run --rm \
  -v /tmp/test-read.txt:/data/test.txt:ro \
  alpine cat /data/test.txt

# Expected output: "Hello from host"
```

**Test Steps - Firecracker Mode**:
```bash
# 1. Same test file from above

# 2. Run with Firecracker runtime
docker run --rm \
  --runtime=runcvm \
  -e RUNCVM_HYPERVISOR=firecracker \
  -v /tmp/test-read.txt:/data/test.txt:ro \
  alpine cat /data/test.txt

# Expected output: "Hello from host"
```

**Verification**:
```bash
# Verify output matches
test "$(cat /tmp/test-read.txt)" = "Hello from host" && echo "PASS" || echo "FAIL"
```

**Expected Results**:
- [PASS] Standard Docker: PASS
- [TARGET] Firecracker: PASS (after Week 1 implementation)

**Performance Metrics**:
- No performance degradation vs standard Docker

### NFS-001: NFS Daemon Verification

**Objective**: Verify `unfsd` is running correctly for the container.

**Test Steps**:
```bash
# 1. Run container
CID=$(docker run -d --runtime=runcvm -e RUNCVM_HYPERVISOR=firecracker -v /tmp:/data alpine sleep 3600)

# 2. Check for process directly
if pgrep -a "unfsd" | grep "firecracker-$CID"; then
  echo "[PASS] unfsd process found"
else
  echo "[FAIL] unfsd missing"
fi

# 3. Check for exports file
if [ -f "/run/runcvm-nfs/$CID.exports" ]; then
   echo "[PASS] Exports file exists"
else
   echo "[FAIL] Exports file missing"
fi
```

**Expected Results**:
- [PASS] `unfsd` process exists and is linked to the container
- [PASS] Exports file is created at the correct location

---

### BM-002: Bind Mount (Read-Write)

**Objective**: Verify write capabilities in bind mounts

**Test Steps - Standard Docker**:
```bash
# 1. Create test directory
mkdir -p /tmp/test-rw
echo "initial" > /tmp/test-rw/data.txt

# 2. Run container and modify file
docker run --rm \
  -v /tmp/test-rw:/data \
  alpine sh -c 'echo "modified from container" >> /data/data.txt'

# 3. Verify changes on host
cat /tmp/test-rw/data.txt
```

**Test Steps - Firecracker Mode**:
```bash
# 1. Same setup

# 2. Run with Firecracker
docker run --rm \
  --runtime=runcvm \
  -e RUNCVM_HYPERVISOR=firecracker \
  -v /tmp/test-rw:/data \
  alpine sh -c 'echo "modified from Firecracker" >> /data/data.txt'

# 3. Verify changes
cat /tmp/test-rw/data.txt
```

**Verification Script**:
```bash
#!/bin/bash
# verify-rw-mount.sh

TEST_DIR="/tmp/test-rw-$$"
mkdir -p "$TEST_DIR"
echo "initial" > "$TEST_DIR/data.txt"

# Function to test a runtime
test_runtime() {
    local runtime=$1
    local hypervisor=$2
    local marker=$3
    
    if [ "$runtime" = "standard" ]; then
        docker run --rm -v "$TEST_DIR:/data" alpine \
          sh -c "echo '$marker' >> /data/data.txt"
    else
        docker run --rm --runtime=runcvm \
          -e RUNCVM_HYPERVISOR=$hypervisor \
          -v "$TEST_DIR:/data" alpine \
          sh -c "echo '$marker' >> /data/data.txt"
    fi
    
    # Verify marker exists
    if grep -q "$marker" "$TEST_DIR/data.txt"; then
        echo "[PASS] $runtime: PASS"
    else
        echo "[FAIL] $runtime: FAIL"
    fi
}

# Test both runtimes
test_runtime "standard" "" "standard-marker"
test_runtime "firecracker" "firecracker" "fc-marker"

# Cleanup
rm -rf "$TEST_DIR"
```

**Expected Results**:
- [PASS] File content modified by container visible on host
- [PASS] Changes persist after container exits
- [PASS] File permissions preserved

---

### BM-003: Bind Mount (Read-Only)

**Objective**: Verify read-only enforcement

**Test Steps - All Runtimes**:
```bash
#!/bin/bash
# test-readonly-mount.sh

TEST_FILE="/tmp/readonly-test.txt"
echo "immutable" > "$TEST_FILE"

# Function to test read-only enforcement
test_readonly() {
    local name=$1
    local cmd=$2
    
    echo "Testing $name..."
    
    # Try to write (should fail)
    if $cmd 2>&1 | grep -qi "read-only\|permission denied"; then
        echo "[PASS] $name: Read-only enforced correctly"
    else
        echo "[FAIL] $name: Read-only NOT enforced"
    fi
}

# Standard Docker
test_readonly "Standard Docker" \
  "docker run --rm -v $TEST_FILE:/data/test.txt:ro alpine sh -c 'echo new > /data/test.txt'"

# Firecracker
test_readonly "Firecracker" \
  "docker run --rm --runtime=runcvm -e RUNCVM_HYPERVISOR=firecracker -v $TEST_FILE:/data/test.txt:ro alpine sh -c 'echo new > /data/test.txt'"

# Verify original file unchanged
if [ "$(cat $TEST_FILE)" = "immutable" ]; then
    echo "[PASS] Original file unchanged"
else
    echo "[FAIL] Original file was modified!"
fi

rm -f "$TEST_FILE"
```

**Expected Results**:
- [PASS] Write attempts fail with permission error
- [PASS] Original file remains unchanged
- [PASS] Read operations succeed

---

### BM-004: Multiple Bind Mounts

**Objective**: Verify multiple volumes can be mounted simultaneously

**Test Script**:
```bash
#!/bin/bash
# test-multiple-mounts.sh

# Setup
mkdir -p /tmp/mount-{1,2,3}
echo "data1" > /tmp/mount-1/file1.txt
echo "data2" > /tmp/mount-2/file2.txt
echo "data3" > /tmp/mount-3/file3.txt

test_multiple_mounts() {
    local runtime=$1
    local hypervisor=$2
    
    if [ "$runtime" = "standard" ]; then
        RESULT=$(docker run --rm \
          -v /tmp/mount-1:/m1 \
          -v /tmp/mount-2:/m2 \
          -v /tmp/mount-3:/m3 \
          alpine sh -c 'cat /m1/file1.txt /m2/file2.txt /m3/file3.txt')
    else
        RESULT=$(docker run --rm --runtime=runcvm \
          -e RUNCVM_HYPERVISOR=$hypervisor \
          -v /tmp/mount-1:/m1 \
          -v /tmp/mount-2:/m2 \
          -v /tmp/mount-3:/m3 \
          alpine sh -c 'cat /m1/file1.txt /m2/file2.txt /m3/file3.txt')
    fi
    
    EXPECTED="data1
data2
data3"
    
    if [ "$RESULT" = "$EXPECTED" ]; then
        echo "[PASS] $runtime: Multiple mounts work"
    else
        echo "[FAIL] $runtime: Failed"
        echo "Expected: $EXPECTED"
        echo "Got: $RESULT"
    fi
}

test_multiple_mounts "Standard Docker" ""
test_multiple_mounts "Firecracker" "firecracker"

# Cleanup
rm -rf /tmp/mount-{1,2,3}
```

**Expected Results**:
- [PASS] All 3 mounts accessible simultaneously
- [PASS] No mount conflicts
- [PASS] Each mount isolated from others

---

## Phase 2: Named Volumes

### NV-001: Create Named Volume

**Objective**: Test named volume creation and basic usage

**Test Steps - Standard Docker**:
```bash
# 1. Create volume
docker volume create test-volume

# 2. Verify volume exists
docker volume ls | grep test-volume

# 3. Inspect volume
docker volume inspect test-volume

# 4. Use volume
docker run --rm -v test-volume:/data alpine sh -c 'echo "test" > /data/file.txt'

# 5. Verify data persists
docker run --rm -v test-volume:/data alpine cat /data/file.txt
# Expected: "test"

# 6. Cleanup
docker volume rm test-volume
```

**Test Steps - Firecracker Mode**:
```bash
docker volume create test-volume-fc

docker run --rm --runtime=runcvm \
  -e RUNCVM_HYPERVISOR=firecracker \
  -v test-volume-fc:/data \
  alpine sh -c 'echo "firecracker test" > /data/file.txt'

docker run --rm --runtime=runcvm \
  -e RUNCVM_HYPERVISOR=firecracker \
  -v test-volume-fc:/data \
  alpine cat /data/file.txt

docker volume rm test-volume-fc
```

**Automated Test**:
```bash
#!/bin/bash
# test-named-volumes.sh

test_named_volume() {
    local runtime=$1
    local hypervisor=$2
    local vol_name="test-vol-${runtime}-$$"
    
    # Create volume
    docker volume create "$vol_name"
    
    # Write data
    local write_cmd="echo 'persistent data' > /data/test.txt"
    if [ "$runtime" = "standard" ]; then
        docker run --rm -v "$vol_name:/data" alpine sh -c "$write_cmd"
    else
        docker run --rm --runtime=runcvm \
          -e RUNCVM_HYPERVISOR=$hypervisor \
          -v "$vol_name:/data" alpine sh -c "$write_cmd"
    fi
    
    # Read data in new container
    if [ "$runtime" = "standard" ]; then
        RESULT=$(docker run --rm -v "$vol_name:/data" alpine cat /data/test.txt)
    else
        RESULT=$(docker run --rm --runtime=runcvm \
          -e RUNCVM_HYPERVISOR=$hypervisor \
          -v "$vol_name:/data" alpine cat /data/test.txt)
    fi
    
    # Verify
    if [ "$RESULT" = "persistent data" ]; then
        echo "√¢≈ì‚Ä¶ $runtime: Named volume persistence works"
    else
        echo "‚ùå $runtime: Failed - got '$RESULT'"
    fi
    
    # Cleanup
    docker volume rm "$vol_name"
}

test_named_volume "standard" ""
test_named_volume "firecracker" "firecracker"
```

**Expected Results**:
- √¢≈ì‚Ä¶ Volume created successfully
- √¢≈ì‚Ä¶ Data persists between container runs
- √¢≈ì‚Ä¶ Volume can be deleted cleanly

---

### NV-003: Volume Persistence Across Container Lifecycle

**Objective**: Verify data persists through start/stop/restart cycles

**Test Script**:
```bash
#!/bin/bash
# test-volume-persistence.sh

test_persistence() {
    local runtime=$1
    local hypervisor=$2
    local vol_name="persist-test-${runtime}-$$"
    local container_name="persist-container-$$"
    
    echo "Testing $runtime persistence..."
    
    # Create volume
    docker volume create "$vol_name"
    
    # Start container with volume
    if [ "$runtime" = "standard" ]; then
        docker run -d --name "$container_name" \
          -v "$vol_name:/data" \
          alpine sleep 3600
    else
        docker run -d --name "$container_name" \
          --runtime=runcvm \
          -e RUNCVM_HYPERVISOR=$hypervisor \
          -v "$vol_name:/data" \
          alpine sleep 3600
    fi
    
    # Write data
    docker exec "$container_name" sh -c 'echo "iteration-1" > /data/counter.txt'
    
    # Stop container
    docker stop "$container_name"
    
    # Start container again
    docker start "$container_name"
    
    # Verify data persists
    RESULT=$(docker exec "$container_name" cat /data/counter.txt)
    
    if [ "$RESULT" = "iteration-1" ]; then
        echo "√¢≈ì‚Ä¶ $runtime: Data persisted after stop/start"
    else
        echo "‚ùå $runtime: Data lost! Got '$RESULT'"
    fi
    
    # Append more data
    docker exec "$container_name" sh -c 'echo "iteration-2" >> /data/counter.txt'
    
    # Restart container
    docker restart "$container_name"
    
    # Verify both iterations
    RESULT=$(docker exec "$container_name" cat /data/counter.txt)
    EXPECTED="iteration-1
iteration-2"
    
    if [ "$RESULT" = "$EXPECTED" ]; then
        echo "√¢≈ì‚Ä¶ $runtime: Data persisted after restart"
    else
        echo "‚ùå $runtime: Data corrupted after restart"
    fi
    
    # Cleanup
    docker stop "$container_name"
    docker rm "$container_name"
    docker volume rm "$vol_name"
}

test_persistence "standard" ""
test_persistence "firecracker" "firecracker"
```

**Expected Results**:
- √¢≈ì‚Ä¶ Data survives container stop
- √¢≈ì‚Ä¶ Data survives container restart
- √¢≈ì‚Ä¶ Data survives container removal (volume persists)

---

## Phase 3: tmpfs Mounts

### TF-001: Basic tmpfs Mount

**Objective**: Verify tmpfs mounts work and data is volatile

**Test Script**:
```bash
#!/bin/bash
# test-tmpfs.sh

set -e
RUNTIME=${RUNTIME:-runcvm}
HYPERVISOR=${RUNCVM_HYPERVISOR:-firecracker}
TEST_NAME="tmpfs-test-$$"

cleanup() {
    docker rm -f "$TEST_NAME" >/dev/null 2>&1 || true
}
trap cleanup EXIT

echo "Testing $RUNTIME tmpfs..."

# Create container with tmpfs
docker run -d --name "$TEST_NAME" \
  --runtime="$RUNTIME" \
  -e RUNCVM_HYPERVISOR="$HYPERVISOR" \
  --tmpfs /tmp:rw,size=100m \
  alpine sleep 3600

# Write to tmpfs
docker exec "$TEST_NAME" sh -c 'echo "tmpfs data" > /tmp/test.txt'

# Verify write succeeded
RESULT=$(docker exec "$TEST_NAME" cat /tmp/test.txt)
if [ "$RESULT" = "tmpfs data" ]; then
    echo "‚úÖ tmpfs write works"
else
    echo "‚ùå tmpfs write failed"
    exit 1
fi

# Restart container (data should be lost)
docker restart "$TEST_NAME"

# Check if data is gone
if docker exec "$TEST_NAME" test -f /tmp/test.txt 2>/dev/null; then
    echo "‚ùå tmpfs data persisted (should be volatile!)"
    exit 1
else
    echo "‚úÖ tmpfs data correctly volatile"
fi
```

**Expected Results**:
- √¢≈ì‚Ä¶ tmpfs mount accessible
- √¢≈ì‚Ä¶ Data written successfully
- √¢≈ì‚Ä¶ Data lost after restart (volatile)
- √¢≈ì‚Ä¶ Size limit enforced

---

### TF-002: tmpfs Size Limit

**Objective**: Verify size limits are enforced

**Test Script**:
```bash
#!/bin/bash
# test-tmpfs-size.sh

test_tmpfs_limit() {
    local runtime=$1
    local hypervisor=$2
    
    echo "Testing $runtime tmpfs size limit..."
    
    # Create container with 50MB tmpfs
    if [ "$runtime" = "standard" ]; then
        CMD="docker run --rm --tmpfs /tmp:rw,size=50m alpine"
    else
        CMD="docker run --rm --runtime=runcvm -e RUNCVM_HYPERVISOR=$hypervisor --tmpfs /tmp:rw,size=50m alpine"
    fi
    
    # Try to write 100MB (should fail)
    if $CMD sh -c 'dd if=/dev/zero of=/tmp/big.file bs=1M count=100' 2>&1 | grep -qi "no space left\|disk full"; then
        echo "√¢≈ì‚Ä¶ $runtime: Size limit enforced"
    else
        echo "‚ùå $runtime: Size limit NOT enforced"
    fi
}

test_tmpfs_limit "standard" ""
test_tmpfs_limit "firecracker" "firecracker"
```

**Expected Results**:
- √¢≈ì‚Ä¶ Writes fail when size exceeded
- √¢≈ì‚Ä¶ Appropriate error message
- √¢≈ì‚Ä¶ Container doesn't crash

---

## Phase 4: Rootfs Caching (Firecracker Only)

### RC-001: Cold Boot Performance

**Objective**: Measure first-time boot performance

**Test Script**:
```bash
#!/bin/bash
# test-cold-boot.sh

set -e
RUNTIME=${RUNTIME:-runcvm}
HYPERVISOR=${RUNCVM_HYPERVISOR:-firecracker}

# Clear any existing cache
sudo rm -rf /var/lib/runcvm/cache/* >/dev/null 2>&1 || true

IMAGE="alpine:latest"
echo "Testing cold boot: $IMAGE"

# Pull image if not present
docker pull "$IMAGE" >/dev/null 2>&1

# Measure cold boot
START=$(date +%s%N)
docker run --rm --runtime="$RUNTIME" \
  -e RUNCVM_HYPERVISOR="$HYPERVISOR" \
  "$IMAGE" echo "ready" >/dev/null 2>&1
END=$(date +%s%N)

DURATION=$(( (END - START) / 1000000 )) # Convert to ms

if [ $DURATION -lt 2000 ]; then # Relaxed target
    echo "‚úÖ $IMAGE: ${DURATION}ms"
else
    echo "‚ö†Ô∏è  $IMAGE: ${DURATION}ms (slow)"
fi
```

**Expected Results**:
- √¢≈ì‚Ä¶ First boot < 500ms
- √¢≈ì‚Ä¶ Cache created in /var/lib/runcvm/cache/
- √¢≈ì‚Ä¶ Rootfs image generated

---

### RC-002: Warm Boot Performance

**Objective**: Measure cached boot performance

**Test Script**:
```bash
#!/bin/bash
# test-warm-boot.sh

IMAGE="alpine:latest"

# Do one cold boot to create cache
docker run --rm --runtime=runcvm \
  -e RUNCVM_HYPERVISOR=firecracker \
  "$IMAGE" echo "warming cache" >/dev/null 2>&1

# Measure 10 warm boots
TOTAL=0
for i in {1..10}; do
    START=$(date +%s%N)
    docker run --rm --runtime=runcvm \
      -e RUNCVM_HYPERVISOR=firecracker \
      "$IMAGE" echo "ready" >/dev/null 2>&1
    END=$(date +%s%N)
    
    DURATION=$(( (END - START) / 1000000 ))
    TOTAL=$((TOTAL + DURATION))
    echo "Boot $i: ${DURATION}ms"
done

AVERAGE=$((TOTAL / 10))

echo "Average warm boot: ${AVERAGE}ms"

if [ $AVERAGE -lt 150 ]; then
    echo "√¢≈ì‚Ä¶ Warm boot performance: ${AVERAGE}ms (target: <150ms)"
else
    echo "‚ö†Ô∏è  Warm boot: ${AVERAGE}ms (exceeds 150ms target)"
fi
```

**Expected Results**:
- √¢≈ì‚Ä¶ Warm boot < 150ms average
- √¢≈ì‚Ä¶ >3x speedup vs cold boot
- √¢≈ì‚Ä¶ Consistent performance across runs

---

## Phase 5: Database Persistence

### DP-001: MySQL Persistence

**Objective**: Verify MySQL data persists across restarts

**Test Script**:
```bash
#!/bin/bash
# test-mysql-persistence.sh

set -e
RUNTIME=${RUNTIME:-runcvm}
HYPERVISOR=${RUNCVM_HYPERVISOR:-firecracker}
VOL_NAME="mysql-data-$$"
CONTAINER_NAME="mysql-test-$$"

cleanup() {
    docker rm -f "$CONTAINER_NAME" >/dev/null 2>&1 || true
    docker volume rm -f "$VOL_NAME" >/dev/null 2>&1 || true
}
trap cleanup EXIT

echo "Testing $RUNTIME with MySQL..."
docker volume create "$VOL_NAME"

# Start MySQL
docker run -d --name "$CONTAINER_NAME" \
  --runtime="$RUNTIME" \
  -e RUNCVM_HYPERVISOR="$HYPERVISOR" \
  -e MYSQL_ROOT_PASSWORD=secret \
  -v "$VOL_NAME:/var/lib/mysql" \
  mysql:8.0

echo "Waiting for MySQL to start..."
# Wait loop
for i in {1..60}; do
    if docker exec "$CONTAINER_NAME" mysqladmin ping -h localhost -u root -psecret --silent; then
        break
    fi
    sleep 1
done

# Create data
docker exec "$CONTAINER_NAME" mysql -uroot -psecret -e "
    CREATE DATABASE testdb;
    USE testdb;
    CREATE TABLE users (id INT, name VARCHAR(50));
    INSERT INTO users VALUES (1, 'Alice');
"

# Restart
echo "Restarting MySQL..."
docker restart "$CONTAINER_NAME"
sleep 10 # Allow restart

# Verify
RESULT=$(docker exec "$CONTAINER_NAME" mysql -uroot -psecret -e "SELECT name FROM testdb.users WHERE id=1" -sN)
if [ "$RESULT" = "Alice" ]; then
    echo "‚úÖ MySQL data persisted"
else
    echo "‚ùå MySQL data lost"
    exit 1
fi
```

**Expected Results**:
- √¢≈ì‚Ä¶ MySQL starts successfully
- √¢≈ì‚Ä¶ Data written to database
- √¢≈ì‚Ä¶ Data survives restart
- √¢≈ì‚Ä¶ No data corruption

---

### DP-002: PostgreSQL Persistence

**Test Script**:
```bash
#!/bin/bash
# test-postgres-persistence.sh

set -e
RUNTIME=${RUNTIME:-runcvm}
HYPERVISOR=${RUNCVM_HYPERVISOR:-firecracker}
VOL_NAME="pg-data-$$"
CONTAINER_NAME="pg-test-$$"

cleanup() {
    docker rm -f "$CONTAINER_NAME" >/dev/null 2>&1 || true
    docker volume rm -f "$VOL_NAME" >/dev/null 2>&1 || true
}
trap cleanup EXIT

echo "Testing $RUNTIME with PostgreSQL..."
docker volume create "$VOL_NAME"

docker run -d --label runcvm-test=true --name "$CONTAINER_NAME" \
  --runtime="$RUNTIME" \
  -e RUNCVM_HYPERVISOR="$HYPERVISOR" \
  -e POSTGRES_PASSWORD=secret \
  -v "$VOL_NAME:/var/lib/postgresql/data" \
  postgres:alpine

echo "Waiting for PostgreSQL..."
# Wait loop
for i in {1..60}; do
    if docker exec "$CONTAINER_NAME" PGPASSWORD=secret psql -U postgres -c "\l" >/dev/null 2>&1; then
        break
    fi
    sleep 1
done

# Create data
docker exec "$CONTAINER_NAME" PGPASSWORD=secret psql -U postgres -c "
    CREATE TABLE products (id INT, name VARCHAR(50));
    INSERT INTO products VALUES (1, 'Laptop');
"

# Restart
echo "Restarting PostgreSQL..."
docker restart "$CONTAINER_NAME"
sleep 10

# Verify
RESULT=$(docker exec "$CONTAINER_NAME" PGPASSWORD=secret psql -U postgres -tAc "SELECT COUNT(*) FROM products")
if [ "$RESULT" = "1" ]; then
    echo "‚úÖ PostgreSQL data persisted"
else
    echo "‚ùå PostgreSQL data lost"
    exit 1
fi
```

**Expected Results**:
- √¢≈ì‚Ä¶ PostgreSQL starts correctly
- √¢≈ì‚Ä¶ Data persists after stop/start
- √¢≈ì‚Ä¶ No WAL corruption
- √¢≈ì‚Ä¶ Proper shutdown/startup sequence

---

## Performance Benchmarks

### Storage I/O Performance

**Test Script**:
```bash
#!/bin/bash
# benchmark-storage-io.sh

benchmark_io() {
    local runtime=$1
    local hypervisor=$2
    local vol_name="benchmark-$$"
    
    docker volume create "$vol_name"
    
    echo "Benchmarking $runtime..."
    
    # Write test
    if [ "$runtime" = "standard" ]; then
        WRITE_TIME=$(docker run --rm -v "$vol_name:/data" alpine \
          sh -c 'time dd if=/dev/zero of=/data/test bs=1M count=100' 2>&1 | \
          grep real | awk '{print $2}')
    else
        WRITE_TIME=$(docker run --rm --runtime=runcvm \
          -e RUNCVM_HYPERVISOR=$hypervisor \
          -v "$vol_name:/data" alpine \
          sh -c 'time dd if=/dev/zero of=/data/test bs=1M count=100' 2>&1 | \
          grep real | awk '{print $2}')
    fi
    
    # Read test
    if [ "$runtime" = "standard" ]; then
        READ_TIME=$(docker run --rm -v "$vol_name:/data" alpine \
          sh -c 'time dd if=/data/test of=/dev/null bs=1M' 2>&1 | \
          grep real | awk '{print $2}')
    else
        READ_TIME=$(docker run --rm --runtime=runcvm \
          -e RUNCVM_HYPERVISOR=$hypervisor \
          -v "$vol_name:/data" alpine \
          sh -c 'time dd if=/data/test of=/dev/null bs=1M' 2>&1 | \
          grep real | awk '{print $2}')
    fi
    
    echo "$runtime - Write: $WRITE_TIME, Read: $READ_TIME"
    
    docker volume rm "$vol_name"
}

benchmark_io "standard" ""
benchmark_io "firecracker" "firecracker"
```

**Target Metrics**:
- Firecracker I/O performance: 90%+ of standard Docker
- Sequential read: >500 MB/s
- Sequential write: >300 MB/s

---

## Verification Methods

### 1. Automated Test Suite

```bash
#!/bin/bash
# run-all-storage-tests.sh

set -e

echo "========================================="
echo "Storage Test Suite - RunCVM"
echo "========================================="
echo ""

# Array to track results
declare -A RESULTS

run_test() {
    local test_name=$1
    local test_script=$2
    
    echo "Running: $test_name"
    if $test_script; then
        RESULTS[$test_name]="PASS"
        echo "√¢≈ì‚Ä¶ $test_name: PASS"
    else
        RESULTS[$test_name]="FAIL"
        echo "‚ùå $test_name: FAIL"
    fi
    echo ""
}

# Run all tests
run_test "Bind Mounts - Read" "./test-bind-mount-read.sh"
run_test "Bind Mounts - Write" "./test-bind-mount-write.sh"
run_test "Bind Mounts - Read-Only" "./test-readonly-mount.sh"
run_test "Multiple Bind Mounts" "./test-multiple-mounts.sh"
run_test "Named Volumes" "./test-named-volumes.sh"
run_test "Volume Persistence" "./test-volume-persistence.sh"
run_test "tmpfs Mounts" "./test-tmpfs.sh"
run_test "tmpfs Size Limit" "./test-tmpfs-size.sh"
run_test "Cold Boot Performance" "./test-cold-boot.sh"
run_test "Warm Boot Performance" "./test-warm-boot.sh"
run_test "MySQL Persistence" "./test-mysql-persistence.sh"
run_test "PostgreSQL Persistence" "./test-postgres-persistence.sh"

# Summary
echo "========================================="
echo "Test Summary"
echo "========================================="
PASS_COUNT=0
FAIL_COUNT=0

for test in "${!RESULTS[@]}"; do
    if [ "${RESULTS[$test]}" = "PASS" ]; then
        echo "√¢≈ì‚Ä¶ $test"
        ((PASS_COUNT++))
    else
        echo "‚ùå $test"
        ((FAIL_COUNT++))
    fi
done

echo ""
echo "Total: $((PASS_COUNT + FAIL_COUNT)) tests"
echo "Passed: $PASS_COUNT"
echo "Failed: $FAIL_COUNT"
echo ""

if [ $FAIL_COUNT -eq 0 ]; then
    echo "√¢≈ì‚Ä¶ All tests passed!"
    exit 0
else
    echo "‚ùå Some tests failed"
    exit 1
fi
```

### 2. Manual Verification Checklist

```markdown
## Week 1 Verification (Bind Mounts)
- [ ] Simple bind mount works
- [ ] Read-write operations succeed
- [ ] Read-only enforcement works
- [ ] Multiple mounts simultaneously
- [ ] File permissions preserved
- [ ] Changes visible on host immediately

## Week 2 Verification (Named Volumes)
- [ ] Volume creation succeeds
- [ ] Volume listing shows new volume
- [ ] Data persists between containers
- [ ] Volume can be shared
- [ ] Volume deletion works
- [ ] No data leaks after deletion

## Week 3 Verification (tmpfs + Caching)
- [ ] tmpfs mount works
- [ ] Data is truly volatile
- [ ] Size limits enforced
- [ ] Cold boot < 500ms
- [ ] Warm boot < 150ms
- [ ] Cache invalidation works

## Week 4 Verification (Databases)
- [ ] MySQL starts successfully
- [ ] MySQL data persists
- [ ] PostgreSQL starts successfully
- [ ] PostgreSQL data persists
- [ ] No corruption after restart
- [ ] Transaction integrity maintained
```

### 3. Performance Comparison Tool

```bash
#!/bin/bash
# compare-runtimes.sh

compare_performance() {
    local test_name=$1
    local test_command=$2
    
    echo "Comparing: $test_name"
    echo "------------------------"
    
    # Standard Docker
    START=$(date +%s%N)
    eval "docker run --rm $test_command" > /dev/null 2>&1
    END=$(date +%s%N)
    STANDARD_TIME=$(( (END - START) / 1000000 ))
    
    # Firecracker
    START=$(date +%s%N)
    eval "docker run --rm --runtime=runcvm -e RUNCVM_HYPERVISOR=firecracker $test_command" > /dev/null 2>&1
    END=$(date +%s%N)
    FC_TIME=$(( (END - START) / 1000000 ))
    
    # Calculate percentages
    FC_PCT=$(( (FC_TIME * 100) / STANDARD_TIME ))
    
    echo "Standard Docker: ${STANDARD_TIME}ms (baseline)"
    echo "Firecracker:    ${FC_TIME}ms (${FC_PCT}% of baseline)"
    echo ""
}

# Run comparisons
compare_performance "Boot time" "alpine echo ready"
compare_performance "Volume mount" "-v /tmp:/data alpine ls /data"
compare_performance "File write" "-v /tmp:/data alpine sh -c 'dd if=/dev/zero of=/data/test bs=1M count=10'"
```

---

## Expected Results Matrix

### Week 1 Target (Dec 7 - Dec 14)

| Feature | Standard Docker | Firecracker | Notes |
|---------|----------------|-------------|-------|
| Simple bind mount | DONE | TARGET | Read-only access |
| Read-write mount | DONE | TARGET | Bidirectional |
| Read-only enforcement | DONE | TARGET | Permissions |
| Multiple mounts | DONE | TARGET | 3+ simultaneous |

### Week 2 Target (Dec 15 - Dec 21)

| Feature | Standard Docker | Firecracker | Notes |
|---------|----------------|-------------|-------|
| Named volume create | DONE | TARGET | docker volume create |
| Named volume use | DONE | TARGET | -v name:/path |
| Volume persistence | DONE | TARGET | Across restarts |
| Volume sharing | DONE | TARGET | Multiple containers |

### Week 3 Target (Dec 22 - Dec 28)

| Feature | Standard Docker | Firecracker | Notes |
|---------|----------------|-------------|-------|
| tmpfs mount | DONE | TARGET | Basic functionality |
| tmpfs volatile | DONE | TARGET | Data lost on restart |
| tmpfs size limit | DONE | TARGET | Enforcement |
| Cold boot | <200ms | <500ms | First run |
| Warm boot | <200ms | <150ms | Cached |

### Week 4 Target (Dec 29 - Jan 4)

| Feature | Standard Docker | Firecracker | Notes |
|---------|----------------|-------------|-------|
| MySQL persistence | DONE | TARGET | Full lifecycle |
| PostgreSQL persistence | DONE | TARGET | Full lifecycle |
| Large file I/O | DONE | TARGET | 100MB+ files |
| I/O performance | 100% | 90%+ | Vs baseline |

---

## Test Execution Schedule

### Daily Tests (Quick Smoke Tests)
```bash
# Run these every day (< 5 minutes)
./quick-smoke-test.sh
```

Contents of `quick-smoke-test.sh`:
```bash
#!/bin/bash
echo "Quick smoke test for storage..."

# Test 1: Basic boot
docker run --rm --runtime=runcvm -e RUNCVM_HYPERVISOR=firecracker alpine echo "OK"

# Test 2: Simple bind mount
echo "test" > /tmp/smoke-test.txt
docker run --rm --runtime=runcvm -e RUNCVM_HYPERVISOR=firecracker \
  -v /tmp/smoke-test.txt:/data/test.txt alpine cat /data/test.txt

# Test 3: Boot time check
time docker run --rm --runtime=runcvm -e RUNCVM_HYPERVISOR=firecracker \
  alpine echo "ready"

rm /tmp/smoke-test.txt
echo "‚úÖ Smoke test complete"
```

### Weekly Tests (Comprehensive)
```bash
# Run these every Friday (~ 30 minutes)
./run-all-storage-tests.sh
```

### Milestone Tests (End of Each Week)
```bash
# Week 1: Bind mounts
./test-bind-mounts-complete.sh

# Week 2: Named volumes
./test-named-volumes-complete.sh

# Week 3: Performance + tmpfs
./test-performance-complete.sh

# Week 4: Database workloads
./test-database-complete.sh
```

---

## Success Criteria Summary

### ‚úÖ Minimum Viable Product (MVP)
- All bind mount types work
- Named volumes functional
- Data persists across restarts
- No data corruption
- Basic documentation

### üéØ Target Goals
- Cold boot < 500ms
- Warm boot < 150ms
- I/O performance ‚â• 90% of standard Docker
- All database workloads pass
- Complete test coverage

### üåü Stretch Goals
- Cold boot < 300ms
- Warm boot < 100ms
- I/O performance ‚â• 95% of standard Docker
- Automated performance regression detection
- CI/CD integration

---

## Troubleshooting Guide

### Common Issues and Solutions

**Issue**: Bind mount not visible in container
```bash
# Debug steps:
1. Check if path exists on host
ls -la /host/path

2. Verify mount in container
docker exec <container> ls -la /container/path

3. Check runcvm logs
journalctl -u runcvm -f

4. Enable debug mode
RUNCVM_DEBUG=1 docker run --runtime=runcvm ...
```

**Issue**: Named volume data not persisting
```bash
# Verify volume exists
docker volume ls | grep volume-name

# Inspect volume
docker volume inspect volume-name

# Check volume mountpoint
sudo ls -la /var/lib/docker/volumes/volume-name/_data

# For Firecracker, check virtio-blk devices
ls -la /var/lib/runcvm/volumes/
```

**Issue**: Poor I/O performance
```bash
# Check disk cache settings
cat /sys/block/vda/queue/scheduler

# Monitor I/O
iostat -x 1

# Check for virtio-blk optimization
dmesg | grep virtio
```

---

## Report Template

### Daily Test Report
```markdown
# Storage Test Report - [DATE]

## Quick Smoke Tests
- [ ] Basic boot: PASS/FAIL
- [ ] Bind mount: PASS/FAIL
- [ ] Boot time: XXXms (target: <500ms cold, <150ms warm)

## Issues Found
1. [Description]
   - Severity: High/Medium/Low
   - Impact: [Component affected]
   - Workaround: [If available]

## Next Steps
- [ ] [Action item 1]
- [ ] [Action item 2]
```

### Weekly Test Report
```markdown
# Storage Test Report - Week [N]

## Test Coverage
- Total tests: XX
- Passed: XX
- Failed: XX
- Coverage: XX%

## Performance Metrics
| Metric | Target | Actual | Status |
|--------|--------|--------|--------|
| Cold boot | <500ms | XXXms | √¢≈ì‚Ä¶/‚ùå |
| Warm boot | <150ms | XXXms | √¢≈ì‚Ä¶/‚ùå |
| I/O throughput | 90%+ | XX% | √¢≈ì‚Ä¶/‚ùå |

## Blockers
1. [Blocker description]

## Completed This Week
- [Feature 1]
- [Feature 2]

## Plan for Next Week
- [Task 1]
- [Task 2]
```

---

**Document Version**: 1.0  
**Last Updated**: December 7, 2025  
**Next Review**: December 14, 2025  
**Test Owner**: RunCVM QA Team